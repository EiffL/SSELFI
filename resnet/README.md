# ResNet-50 on TPU

## Prerequisites

### Setup a Google Cloud project

Follow the instructions at the [Quickstart Guide](https://cloud.google.com/tpu/docs/quickstart)
to get a GCE VM with access to Cloud TPU.

To run this model, you will need:

* A GCP project and its associated project ID
* The zone you are planning on using
* A GCE VM instance with an associated Cloud TPU resource

### Formatting the data

The data is expected to be formatted in TFRecord format, as generated by [this
script](https://github.com/tensorflow/tpu-demos/blob/master/cloud_tpu/datasets/imagenet_to_gcs.py).

If you do not have ImageNet dataset prepared, you can use a randomly generated
fake dataset to test the model. It is located at
`gs://cloud-tpu-test-datasets/fake_imagenet`.


## Training the model

First, modify `train_resnet.sh` by assigning appropriate values to the following
lines in the script:

```
PROJECT = 'your-gcp-project'
ZONE = 'your-compute-zone'
TPU_NAME = 'your-assigned-tpu-name'
DATA_DIR = 'gs://path/to/data/dir'
MODEL_DIR = gs://path/to/your/model
```

`PROJECT`, `ZONE`, and `TPU_NAME` should be the same as the values you used to
initialize your GCE VM in the [Quickstart
Guide](https://cloud.google.com/tpu/docs/quickstart).
The data and model directories should be the address to your GCS buckets.

Then run the script via

```
./train_resnet.sh
```

This will train a ResNet-50 model on ImageNet with 1024 batch size on a single
Cloud TPU. With the default flags on everything, the model should train to
above 76% accuracy in around 17 hours (including evaluation time every
`--steps_per_eval` steps).

The script also launches a Tensorboard instance at port 6006. This port is
automatically forwarded to your local machine and can be viewed at
http://localhost:6006.

## Understanding the code

For more detailed information, read the documentation within each file.

* `imagenet_input.py`: Constructs the `tf.data.Dataset` input pipeline which
  handles parsing, preprocessing, shuffling, and batching the data samples.
* `resnet_main.py`: Main code which constructs the TPUEstimator and handles
  training and evaluating the model.
* `resnet_model.py`: ResNet model code which constructs the network via modular
  residual blocks or bottleneck blocks.
* `resnet_preprocessing.py`: Useful utilities for preprocessing and augmenting
  ImageNet data for ResNet training. Significantly improves final accuracy.

## Additional notes

### About the model and training regime

The model is based on network architecture presented in [Deep Residual Learning
for Image Recognition](https://arxiv.org/abs/1512.03385) by Kaiming He, et. al.

Specifically, the model uses post-activation residual units for ResNet-18, and
34 and post-activation bottleneck units for ResNet-50, 101, 152, and 200. There
are a few differences to the model and training compared to the original paper:

* The preprocessing and data augmentation is slightly different. In particular,
  we have an additional step during normalization which rescales the inputs
  based on the stddev of the RGB values of the dataset.
* We use a larger batch size of 1024 (by default) instead of 256 and
  linearly scale the learning rate. In addition, we adopt the learning rate
  schedule suggested by [Accurate, Large Minibatch SGD: Training ImageNet in 1
  Hour](https://arxiv.org/abs/1706.02677) and train for 90 epochs.
* We use a slightly different weight initialization for batch normalization in
  the last batch norm per block, as inspired by the above paper.
* Evaluation is performed on a single center crop of the validation set rather
  than a 10-crop from the original paper.

### Training/evaluating/predicting on CPU/GPU

To run the same code on CPU/GPU, set the flag `--use_tpu=False`. This will use
the default devices available to TensorFlow on your machine. The checkpoints
created by CPU/GPU and TPU are all identical so it is possible to train on one
type of device and then evaluate/predict using the trained model on a different
device.

### Using different ResNet configurations

The default ResNet-50 has been carefully tested with the default flags but
`resnet_model.py` includes a few other commonly used configurations including
ResNet-18, 34, 101, 152, 200. The 18 and 34 layer configurations use residual
blocks without bottlenecks and the remaining configurations use bottleneck
layers. The configuration can be controlled via `--resnet_size`. Bigger models
require more training time and more memory, thus may require lowering the
`--train_batch_size` to prevent running out of memory.

### Using your own data

To use your own data with this model, you first need to write an input pipeline
similar to `imagenet_input.py`. It is recommended to use TFRecord format for
storing your data on disk (see the ImageNet dataset download script for details)
and `tf.data.Dataset` for the actual pipeline. Then, simply replace the current
`imagenet_input` in `resnet_main.py` and adjust the dataset constants.

### Benchmarking the training speed

When benchmarking the training speed, set `--steps_per_eval` to be equal to
`--train_steps` so that all the training completes before evaluation begins. The
steps per second and images per second are logged during training. Total
training time excluding evaluation but including the time it takes to compile
and initialize the graph is also logged and can be explicitly calculated by
subtracting the start timestamp from the end timestamp on the logs.

